{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGnWn97zj20u"
      },
      "source": [
        "#Important datas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNzkWK5sj18V"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from scipy import ndimage as ndi\n",
        "from skimage import io, filters, color, transform\n",
        "import cv2 as cv\n",
        "from scipy.ndimage.morphology import distance_transform_edt\n",
        "from skimage.morphology import erosion, disk\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%matplotlib inline\n",
        "\n",
        "pages = [\"dasrtseldesjdisc00frit_0007\", \"dasrtseldesjdisc00frit_0008\", \"dasrtseldesjdisc00frit_0009\", \"dasrtseldesjdisc00frit_0010\", \"dasrtseldesjdisc00frit_0011\"]\n",
        "\n",
        "#TODO: Poniżej należy podać ścieżkę do głównego folderu\n",
        "folder_path = \"FolderGlowny\"\n",
        "columns=['Char', 'Image']\n",
        "sizes = range(4, 71)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whVelUVFybGw"
      },
      "outputs": [],
      "source": [
        "# module level variables ##########################################################################\n",
        "#Size of the digit\n",
        "#max numbers of one char \n",
        "max_size = 100\n",
        "#enable chars\n",
        "enable_chars = ['A', 'a', 'B', 'b', 'C', 'c', 'D', 'd', 'E', 'e', 'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n', 'O', 'o', 'P', 'p',\n",
        "                'R', 'r', 'S', 's', 'T', 't', 'U', 'u', 'W', 'w', 'Y', 'y', 'Z', 'z', 'Ä', 'ä', 'Ö', 'ö', 'Q', 'q', 'ẞ', 'ß', 'Ü', 'ü', 'V', 'v', 'X', 'x', '1','2','3', '4', \n",
        "                '5', '6', '7', '8', '9', '0', ',', '.', '(', ')', '-', '\\'', '\\\"','+', '=','#', '^', '*', '?', '[', ']', '%', ':',';',\n",
        "                'ch', 'ck', 'st', 'll', 'ss', 'fi', 'si', 'ff', 'fl']\n",
        "x = {char: [] for char in enable_chars}\n",
        "###################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqgk6tA5Dog"
      },
      "outputs": [],
      "source": [
        "def save_to_npz_file(x_train, x_test, y_train, y_test, size):\n",
        "\n",
        "    result_file_path = folder_path+ '/TrainingFiles/Final/' + str(size) + '.npz'\n",
        "    np.savez_compressed(result_file_path,\n",
        "                    x_train = x_train,x_test = x_test, y_train = y_train,  y_test = y_test)\n",
        "    \n",
        "def load_to_npz_file(size):\n",
        "    NPZFile = np.load(folder_path+ '/TrainingFiles/Final/' + str(size) + '.npz', allow_pickle= True)\n",
        "    x_train, y_train, x_test, y_test = [NPZFile[f] for f in ['x_train', 'y_train', \n",
        "                                    'x_test', 'y_test']]\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80WTbCi1jCNQ"
      },
      "outputs": [],
      "source": [
        "def shuffle(x_train, x_test, y_train, y_test, seed):\n",
        "    x = np.vstack((x_train, x_test))\n",
        "    y = np.hstack([y_train, y_test])\n",
        "    new_x_train, new_x_test, new_y_train, new_y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=seed)\n",
        "    return new_x_train, new_x_test, new_y_train, new_y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyGJTxiScwKt"
      },
      "source": [
        "#Utworzenie finalnych zbiorów danych o określonym rozmiarze przestrzeni cech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOs-LwwbbZ8A"
      },
      "outputs": [],
      "source": [
        "def make_final_data_train_file(X, result_size):\n",
        "    # data_frame = pd.DataFrame(columns=['Vector'])\n",
        "    result_list = []\n",
        "    for x in X:\n",
        "        result_size_image = cv.resize(x, dsize=(result_size, result_size), interpolation=cv.INTER_CUBIC)\n",
        "        vector = result_size_image.reshape((1, (result_size*result_size)))\n",
        "\n",
        "        result_list.append(vector[0])\n",
        "        # data_frame = data_frame.append({'Vector': vector[0]}, ignore_index=True);\n",
        "    return np.array(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoWn2xWucjsN"
      },
      "outputs": [],
      "source": [
        "NPZFile = np.load(folder_path+ '/TrainingFiles/DataTrain(NotResized).npz', allow_pickle= True)\n",
        "X_train, Y_train, X_test, Y_test = [NPZFile[f] for f in ['X_train', 'y_train', \n",
        "                                    'X_test', 'y_test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVxh5G7G3MRe",
        "outputId": "1910cbe6-2ea8-46b7-b217-e3b349172a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n"
          ]
        }
      ],
      "source": [
        "y_test = Y_test\n",
        "y_train = Y_train\n",
        "for size in sizes:\n",
        "    print(size)\n",
        "    x_train = make_final_data_train_file(X_train, size)\n",
        "    x_test = make_final_data_train_file(X_test, size)\n",
        "    save_to_npz_file(x_train, x_test, y_train, y_test, size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFz8tzY6yLdl"
      },
      "source": [
        "# Badania przestrzeni cech\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACe3_6ZcyTDC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "def TestClassifier(classifier, x_test, y_test):\n",
        "\n",
        "    start = time.process_time()\n",
        "    score = classifier.score(x_test, y_test)\n",
        "    time_proces = time.process_time() - start\n",
        "    data = {'Score': [score], 'TestTime': [time_proces]}\n",
        "    resultDf = pd.DataFrame(data = data, columns =['Score', 'TestTime'])\n",
        "    return resultDf\n",
        "def TrainClassifier(classifier, x_train, y_train):\n",
        "\n",
        "    start = time.process_time()\n",
        "    classifier.fit(x_train, y_train)\n",
        "    time_proces = time.process_time() - start   \n",
        "    p = pickle.dumps(classifier)\n",
        "    data = {'TrainingTime': [time_proces], 'ModelSize': [sys.getsizeof(p)]}\n",
        "    resultDf = pd.DataFrame(data = data,columns =['TrainingTime', 'ModelSize'])\n",
        "    return resultDf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KMXwTOZP-aB"
      },
      "outputs": [],
      "source": [
        "def TestSingleClassifier(classifier, x_train, x_test, y_train, y_test):\n",
        "    singleTest = pd.DataFrame(data = [str(classifier)], columns=['Clasifier'])\n",
        "    result = TrainClassifier(classifier, x_train, y_train)\n",
        "    singleTest = pd.concat([singleTest, result], axis=1)\n",
        "    result = TestClassifier(classifier, x_test, y_test)\n",
        "    singleTest = pd.concat([singleTest, result], axis=1)\n",
        "    return singleTest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzj-djbNBv1w",
        "outputId": "8a69bac8-ecdc-4334-8498-9b387a5425a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "classifiers = {KNeighborsClassifier(), SVC()}\n",
        "scores = pd.DataFrame(columns = [\"Score\", \"TestTime\", 'TrainingTime', 'ModelSize', 'Clasifier', 'Seed', 'Size'])\n",
        "seeds = {1,2,3,2077, 4,5,6,7,8, 9}\n",
        "\n",
        "for size in sizes:\n",
        "    print(size)\n",
        "    x_train, x_test, y_train, y_test = load_to_npz_file(size)\n",
        "    stdSC = StandardScaler()\n",
        "    x_train = stdSC.fit_transform(x_train)\n",
        "    x_test = stdSC.fit_transform(x_test)\n",
        "    seedsTest = pd.DataFrame(columns = [\"Score\", \"TestTime\", 'ModelSize', 'TrainingTime', 'Clasifier', 'Seed'])\n",
        "    for seed in seeds:\n",
        "        x_train, x_test, y_train, y_test = shuffle(x_train, x_test, y_train, y_test, seed)\n",
        "        seedTest = pd.DataFrame(columns = [\"Score\", \"TestTime\", 'ModelSize', 'TrainingTime', 'Clasifier'])\n",
        "        for classifier in classifiers:\n",
        "            singleTest = TestSingleClassifier(classifier, x_train, x_test, y_train, y_test)\n",
        "            seedTest = seedTest.append(singleTest)\n",
        "        seedTest['Seed'] = seed\n",
        "        seedsTest = seedsTest.append(seedTest)\n",
        "    seedsTest['Size'] = size\n",
        "    scores = scores.append(seedsTest)\n",
        "    scores.to_csv(folder_path + \"/Result/FeautreSizeTest3.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0NYpZ4iATDF"
      },
      "source": [
        "#Badanie pojedynczego rozmiaru przestrzeni cech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAlbdi5XdYI_"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cDpDo4k5HPi"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def FindBestClassifier(classifierType, params, x_train, y_train):\n",
        "    start = time.process_time()\n",
        "    \n",
        "    classifier = GridSearchCV(\n",
        "        classifierType,\n",
        "        params,\n",
        "        verbose = 2,\n",
        "        cv = 3,\n",
        "        n_jobs = -4)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    searchingTime = time.process_time() - start\n",
        "    params = classifier.best_params_\n",
        "    return params, searchingTime\n",
        "\n",
        "def TestClassifier(classifierType, params, x_train, y_train, x_test, y_test):\n",
        "    classifier = classifierType.set_params(**params)\n",
        "    \n",
        "    classifier.fit(x_train, y_train)\n",
        "    score = classifier.score(x_test, y_test)\n",
        " \n",
        "    y_pred = classifier.predict(x_test)\n",
        "    matrix_of_errors = GetMatrixOfErrors(y_test, y_pred)\n",
        "\n",
        "    return score, matrix_of_errors\n",
        "def TestClassifier(classifier, x_train, y_train, x_test, y_test):\n",
        "    classifier.fit(x_train, y_train)\n",
        "    score = classifier.score(x_test, y_test)\n",
        " \n",
        "    y_pred = classifier.predict(x_test)\n",
        "    matrix_of_errors = GetMatrixOfErrors(y_test, y_pred)\n",
        "\n",
        "    return score, matrix_of_errors\n",
        "\n",
        "def GetMatrixOfErrors(y_test, y_pred):\n",
        "    sorted_chars = np.unique(y_test)\n",
        "    sorted_chars.sort()\n",
        "    matrix_of_errors = pd.DataFrame(0, columns = sorted_chars, index = sorted_chars)\n",
        "    for  (y_test, y_pred) in (zip(y_test, y_pred)):\n",
        "        matrix_of_errors[y_test][y_pred] = matrix_of_errors[y_test][y_pred] + 1\n",
        "    return matrix_of_errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylz-oGy4J3Ak"
      },
      "outputs": [],
      "source": [
        "scoreDf = pd.DataFrame(columns =['Size', 'Score', 'Params', 'SearchingTime', 'Classifier'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC1AmJ1RTw0W"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifierType =  RandomForestClassifier(n_jobs=-4, bootstrap=True)\n",
        "params = {\n",
        "\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'criterion' : ['entropy', 'gini']\n",
        "    'max_depth': [80, 90, 100, 110, 120, 130, 200],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1 ],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cPb8YbJEPoB"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifierType = KNeighborsClassifier()\n",
        "params = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
        "    'weights' : ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "    'metric': ['minkowski', 'cityblock', 'cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMjViYUMBSAQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "classifierType = SVC()\n",
        "params = {\n",
        "        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "        'gamma' : ['scale', 'auto'],\n",
        "        'C':[0.1, 1, 2, 10, 20, 50]\n",
        "    } "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVYQWayELRU5"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifierType = DecisionTreeClassifier()\n",
        "params = {\n",
        "        'criterion' : ['gini','entropy', 'log_loss'],\n",
        "        'splitter': ['best', 'random'],\n",
        "        'max_depth': [10, 50, 100, 200, 500, 1000, None],\n",
        "        'min_samples_split': [1, 2, 5, 10, 20, 50, 100],\n",
        "        'min_samples_leaf': [1, 2, 5, 10, 20, 50, 100],\n",
        "        'max_features': ['auto', 'sqrt', 'log2']\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU2VOWERU4xk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sizes = {15}\n",
        "classifierName = str(classifierType)\n",
        "for size in sizes:\n",
        "    print(size)\n",
        "    x_train, x_test, y_train, y_test = load_to_npz_file(size)\n",
        "    x, y = np.concatenate((x_train, x_test), axis=0), np.concatenate((y_train, y_test), axis=0)\n",
        "    params, searchingTime = FindBestClassifier(classifierType, params, x, y)\n",
        "    score, matrix_of_errors = TestClassifier(classifierType, params, x_train, y_train, x_test, y_test)\n",
        "    matrix_of_errors.to_csv(folder_path + \"/Result/MatrixOfErrors/\" + str(classifierName) + str(size) + \".csv\")\n",
        "\n",
        "    scoreDf = scoreDf.append({'Size': size, 'Score': score, 'Params': params, 'SearchingTime': searchingTime, 'Classifier': classifierName}, ignore_index = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-ICOdhVOZlJ"
      },
      "outputs": [],
      "source": [
        "scoreDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h77hbgLJ1qq"
      },
      "outputs": [],
      "source": [
        "scoreDf.to_csv(folder_path + \"/Result/FindBestParams.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
