{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGnWn97zj20u"
      },
      "source": [
        "#Import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNzkWK5sj18V"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from scipy import ndimage as ndi\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, filters, color, transform\n",
        "import cv2 as cv\n",
        "from scipy.ndimage.morphology import distance_transform_edt\n",
        "from skimage.morphology import erosion, disk\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%matplotlib inline\n",
        "\n",
        "# Nazwy plików, bez rozszerzeń, wykorzystane do utworzenia zbioru danych\n",
        "pages = [\"dasrtseldesjdisc00frit_0007\", \"dasrtseldesjdisc00frit_0008\", \"dasrtseldesjdisc00frit_0009\", \"dasrtseldesjdisc00frit_0010\", \"dasrtseldesjdisc00frit_0011\"]\n",
        "\n",
        "#TODO: Poniżej należy podać ścieżkę do głównego folderu\n",
        "folder_path = \"FolderGlowny\"\n",
        "columns=['Char', 'Image']\n",
        "sizes = range(4, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "401tbU7WerGr"
      },
      "outputs": [],
      "source": [
        "def remove_small_element(binary_tmp, min_size):\n",
        "  #find all your connected components (white blobs in your image)\n",
        "  nb_components, output, stats, centroids = cv.connectedComponentsWithStats(binary_tmp, connectivity=8)\n",
        "  #connectedComponentswithStats yields every seperated component with information on each of them, such as size\n",
        "  #the following part is just taking out the background which is also considered a component, but most of the time we don't want that.\n",
        "  sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
        "\n",
        "  #your answer image\n",
        "  binary_tmp = np.zeros((output.shape))\n",
        "  #for every component in the image, you keep it only if it's above min_size\n",
        "  for i in range(0, nb_components):\n",
        "      if sizes[i] >= min_size:\n",
        "          binary_tmp[output == i + 1] = 255\n",
        "  return  binary_tmp\n",
        "\n",
        "def find_object_in_line(bin_clip, dist):\n",
        "  hist = cv.reduce(bin_clip,0, cv.REDUCE_AVG).reshape(-1)\n",
        "\n",
        "  th = 2\n",
        "  H,W = bin_clip.shape[:2]\n",
        "  left = [x for x in range(W-1) if hist[x]<=th and hist[x+1]>th]\n",
        "  right = [x for x in range(W-1) if hist[x]>th and hist[x+1]<=th]\n",
        "  if len(left) > 0 and len(right) > 0:\n",
        "    mids_vertical = [int(left[0]/2)]\n",
        "    for i in range(1,len(left)):\n",
        "        mid_vertical = int((left[i]+right[i-1])/2)\n",
        "        #if mid_vertical > dist:\n",
        "        mids_vertical.append(mid_vertical)\n",
        "    mid_vertical = int(int(right[len(right)-1] + W)/2)\n",
        "    mids_vertical.append(mid_vertical)\n",
        "    return mids_vertical\n",
        "  return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD-8_QrN6QBl"
      },
      "outputs": [],
      "source": [
        "def read_single_page(page, columns):\n",
        "\n",
        "    resultPath = folder_path+ '/TrainingFiles/AllData.csv'\n",
        "    print(page)\n",
        "    ##########Założenia############\n",
        "    #\n",
        "    #1.Wszystkie litery mają tą samą, poziomą orientację \n",
        "    #2.Na obrazie znajduje się tylko jedna kolumna wierszy \n",
        "    ###########PATH#################\n",
        "    #page = \"dasrtseldesjdisc00frit_0011\"\n",
        "    read_path = folder_path + \"/\" + page + \".jpg\"\n",
        "    text_file_path = folder_path + \"/Source/\" + page + \".txt\"\n",
        "\n",
        "    output_filename = resultPath\n",
        "    ################Images\n",
        "    image_folder_path = folder_path + \"/Result/Images/\"\n",
        "\n",
        "    ###############################\n",
        "    # module level variables ##########################################################################\n",
        "    #Char 'a' size\n",
        "    char_heigh = 40\n",
        "    char_width = 15\n",
        "\n",
        "    MIN_CONTOUR_AREA = 40\n",
        "    MIN_CONTOUR_CHAR = char_heigh*char_width\n",
        "    MIN_DIST_BETWEEN_WORDS = 20 #px\n",
        "    DIST_BETWEN_CHARS = 1 #px\n",
        "    AREA_OVER_CHAR = 0.5*char_heigh\n",
        "    #Size of the digit\n",
        "    #result_img_size = 50\n",
        "    ###################################################################################################\n",
        "    digit = io.imread(read_path)\n",
        "    #print(\"Number of Dimension\", digit.ndim)\n",
        "    #io.imshow(digit)\n",
        "    #io.show()\n",
        "    ########################################\n",
        "    if digit.ndim > 1:\n",
        "        gray_image = color.rgb2gray(digit)\n",
        "    else:\n",
        "        gray_image = digit\n",
        "    #gray_image = cv.GaussianBlur(gray_image, (5,5), 0) \n",
        "    thresh = filters.threshold_minimum(gray_image)\n",
        "\n",
        "    binary_image = gray_image > thresh\n",
        "    #io.imshow(binary_image)\n",
        "    #io.show()\n",
        "    binary = np.invert((binary_image*255).astype('uint8'))\n",
        "    binary_final = remove_small_element(binary, MIN_CONTOUR_AREA)\n",
        "    binary_final = np.invert((binary_final).astype('bool_'))\n",
        "    #######################################\n",
        "    dist_map = distance_transform_edt(binary_final)\n",
        "    tresh_dist_map = dist_map > MIN_DIST_BETWEEN_WORDS/2\n",
        "\n",
        "    #io.imshow(dist_map)\n",
        "    #io.show()\n",
        "    #io.imshow(tresh_dist_map)\n",
        "    #io.show()\n",
        "\n",
        "    neg_tresh_dist_map = np.invert(tresh_dist_map)\n",
        "    mask = np.ones((MIN_DIST_BETWEEN_WORDS,1),np.uint8)\n",
        "    eroded = erosion(neg_tresh_dist_map, mask)\n",
        "    #io.imshow(eroded)\n",
        "    #io.show()\n",
        "    ####################\n",
        "    eroded = (eroded*255).astype('uint8')\n",
        "    ## (5) find and draw the upper and lower boundary of each lines\n",
        "    hist = cv.reduce(eroded,1, cv.REDUCE_AVG).reshape(-1)\n",
        "\n",
        "    th = 2\n",
        "    H,W = digit.shape[:2]\n",
        "    uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
        "    lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
        "\n",
        "    interline = [int(uppers[0]/2)]\n",
        "    for i in range(1,len(uppers)):\n",
        "        mid_horizontal = int((uppers[i]+lowers[i-1])/2)\n",
        "        interline.append(mid_horizontal)\n",
        "    mid_horizontal = int(int(lowers[len(lowers)-1] + H)/2)\n",
        "    interline.append(mid_horizontal)\n",
        "\n",
        "    digit_with_line = digit.copy()\n",
        "    for y in interline:\n",
        "        cv.line(digit_with_line, (0,y), (W, y), (255,0,0),6)\n",
        "\n",
        "    lines = []\n",
        "    for i in range(1, len(interline)):\n",
        "        lines.append((interline[i-1], interline[i]))\n",
        "    #io.imshow(digit_with_line)\n",
        "    #io.show()\n",
        "    #################################\n",
        "    digit_with_word = digit_with_line.copy()\n",
        "    complet_words = []\n",
        "    for line in lines:\n",
        "        line_eroded = eroded[line[0]:line[1],:]\n",
        "        interword = find_object_in_line(line_eroded, MIN_DIST_BETWEEN_WORDS)\n",
        "        interword = np.sort(interword)\n",
        "        word = []\n",
        "        for i in range(1, len(interword)):\n",
        "            word.append((interword[i-1], interword[i]))\n",
        "        complet_words.append((line, word))\n",
        "        for x in interword:\n",
        "            cv.line(digit_with_word, (x,line[0]), (x, line[1]), (255,0,0), 4)\n",
        "    #io.imshow(digit_with_word)\n",
        "    #io.show()  \n",
        "    ##################\n",
        "    digit_with_chars = digit.copy()\n",
        "    text = []\n",
        "    i = 0\n",
        "    for line in complet_words:\n",
        "        up_limit, down_limit = line[0]\n",
        "        single_line = []\n",
        "        i = i + 1\n",
        "        #cv.putText(digit_with_chars, str(i), (10, down_limit),cv.FONT_HERSHEY_COMPLEX, 5, (0,0,255), 4, cv.LINE_AA)\n",
        "        for word in line[1]: \n",
        "            word_image  = (np.invert(binary_final[up_limit:down_limit, word[0]:word[1]])*255).astype('uint8')\n",
        "            interchar = find_object_in_line(word_image, DIST_BETWEN_CHARS)\n",
        "            single_word = []\n",
        "            for i in range(1, len(interchar)):\n",
        "                char = [up_limit, down_limit, interchar[i-1]+ word[0], interchar[i]+word[0]]\n",
        "                single_word.append(char)      \n",
        "                \n",
        "                cv.rectangle(digit_with_chars,(interchar[i-1]+ word[0],up_limit+6),(interchar[i]+word[0], down_limit-6),(0,0,255), 4)\n",
        "            single_line.append(single_word)\n",
        "\n",
        "        #for x in interchar:\n",
        "        #  cv.line(digit_with_chars, (x+ word[0],up_limit), (x+word[0], down_limit), (0,255,0), 4)\n",
        "        text.append(single_line)\n",
        "\n",
        "    #io.imshow(digit_with_chars)\n",
        "    #io.show()  \n",
        "    ############################\n",
        "    text_file = open(text_file_path, \"r\")\n",
        "    text_in_page = text_file.read().split('\\n')\n",
        "    #create feature vector\n",
        "    # bool_x = np.zeros((1,(result_img_size*result_img_size)), dtype='bool_')\n",
        "    # bool_fv = np.zeros((1,(result_img_size*result_img_size)+1), dtype='<U32')\n",
        "    from skimage import  morphology\n",
        "    import pandas as pd\n",
        "    table_of_data = pd.DataFrame(columns=columns)\n",
        "    for num, line_coord in enumerate(text, start = 0):\n",
        "        line_clip = digit_with_chars[line_coord[0][0][0]:line_coord[0][0][1],:]\n",
        "        #io.imshow(line_clip)\n",
        "        #io.show()\n",
        "        line_text = text_in_page[num]\n",
        "        text_in_page.append(line_text)\n",
        "        chars = line_text.split(\" \")\n",
        "        i = 0\n",
        "        char_sum = 0\n",
        "        for word_coord in line_coord:\n",
        "            char_sum = char_sum + len(word_coord)\n",
        "        if len(chars) != char_sum:\n",
        "            print(\"Line \", num, len(chars), char_sum)\n",
        "        else:\n",
        "            try:\n",
        "                for word_coord in line_coord:\n",
        "                    for char_coord in word_coord:\n",
        "                        clip = binary_final[char_coord[0]:char_coord[1],char_coord[2]:char_coord[3]]\n",
        "                        clip = (clip*255).astype('uint8')\n",
        "                        clip = remove_small_element(clip,MIN_CONTOUR_AREA)\n",
        "                        clip = (clip).astype('uint8')\n",
        "                        clip = np.invert(clip)\n",
        "                        clip = remove_small_element(clip,MIN_CONTOUR_AREA)\n",
        "                        clip = (clip).astype('uint8')\n",
        "                        #io.imshow(clip)\n",
        "                        #io.show()\n",
        "                        rows, = np.where(clip.sum(axis=1) > 0)\n",
        "                        columns, = np.where(clip.sum(axis=0) > 0)\n",
        "                        if len(rows) > 1 and len(columns) > 1 and len(rows)*len(columns) > MIN_CONTOUR_AREA:\n",
        "                            tmp_img = clip[rows.min():rows.max(), columns.min():columns.max()]\n",
        "                            tmp_heigh, tmp_width = tmp_img.shape\n",
        "                            centre = ndi.measurements.center_of_mass(tmp_img)\n",
        "                            centre = tuple((round(tup)) for tup in centre)\n",
        "                            dist_row = (tmp_heigh - centre[0], centre[0])\n",
        "                            dist_col = (tmp_width - centre[1], centre[1])\n",
        "                            size = max(max(dist_row)*2, max(dist_col)*2)\n",
        "\n",
        "                            back = np.zeros((size,size), dtype=type(tmp_img[0,0]))\n",
        "                            row_off = round(size - max(dist_row))\n",
        "                            col_off = round(size - max(dist_col))\n",
        "                            \n",
        "                            back[round(size/2 - centre[0]): round(size/2 +  tmp_heigh - centre[0]), \n",
        "                                round(size/2 - centre[1]): round(size/2 + tmp_width - centre[1])] = tmp_img\n",
        "                            single_char_image = back\n",
        "                            kernel = np.ones((3,3))\n",
        "                            single_char_image = cv.morphologyEx(single_char_image.astype('uint8'), cv.MORPH_DILATE, kernel)\n",
        "                            single_char_image = single_char_image/255\n",
        "                            table_of_data = table_of_data.append({'Char': chars[i], 'Image':single_char_image}, ignore_index = True)\n",
        "                            i= i+1\n",
        "            except:\n",
        "                pass\n",
        "        #print(\"##################\")\n",
        "    return table_of_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6gWmNCZfHXj",
        "outputId": "28eec819-fc81-4974-8ed6-1e96139f1f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dasrtseldesjdisc00frit_0007\n",
            "dasrtseldesjdisc00frit_0008\n",
            "dasrtseldesjdisc00frit_0009\n",
            "dasrtseldesjdisc00frit_0010\n",
            "Line  2 2 20\n",
            "Line  15 24 3\n",
            "Line  23 2 22\n",
            "dasrtseldesjdisc00frit_0011\n"
          ]
        }
      ],
      "source": [
        "allDatas = pd.DataFrame(columns=columns)\n",
        "for page in pages:\n",
        "    datas = read_single_page(page, columns)\n",
        "    allDatas = allDatas.append(datas)\n",
        "\n",
        "allDatas.to_csv(path_or_buf=output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQfcMB5NydVG"
      },
      "source": [
        "#Utworzenie zbioru nie przeskalowanych obrazów\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whVelUVFybGw"
      },
      "outputs": [],
      "source": [
        "# module level variables ##########################################################################\n",
        "#Size of the digit\n",
        "#max numbers of one char \n",
        "max_size = 100\n",
        "#enable chars\n",
        "enable_chars = ['A', 'a', 'B', 'b', 'C', 'c', 'D', 'd', 'E', 'e', 'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n', 'O', 'o', 'P', 'p',\n",
        "                'R', 'r', 'S', 's', 'T', 't', 'U', 'u', 'W', 'w', 'Y', 'y', 'Z', 'z', 'Ä', 'ä', 'Ö', 'ö', 'Q', 'q', 'ẞ', 'ß', 'Ü', 'ü', 'V', 'v', 'X', 'x', '1','2','3', '4', \n",
        "                '5', '6', '7', '8', '9', '0', ',', '.', '(', ')', '-', '\\'', '\\\"','+', '=','#', '^', '*', '?', '[', ']', '%', ':',';',\n",
        "                'ch', 'ck', 'st', 'll', 'ss', 'fi', 'si', 'ff', 'fl']\n",
        "x = {char: [] for char in enable_chars}\n",
        "###################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKXSObmj7-Vu",
        "outputId": "e0ac3a67-3e2d-4b38-e2e0-79a0da83461c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "en\n",
            "ro\n",
            "ib\n",
            "ass\n",
            "tio\n",
            "ns\n",
            "us\n",
            "st.\n",
            "be\n",
            "rm\n",
            "li\n",
            "ts\n",
            "un\n",
            "kr\n",
            "ns\n",
            "eh\n",
            "un\n",
            "nn\n",
            "er\n",
            "un\n",
            "rn\n",
            "ti\n",
            "em\n",
            "nn\n",
            "–\n",
            "ass\n",
            "–\n",
            "–\n",
            "[]\n",
            "af\n",
            "ts\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "Er\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "ng\n",
            "aß\n",
            "ltu\n",
            "fa\n",
            "ru\n",
            "Au\n",
            "it\n",
            "ku\n",
            "fü\n",
            "jü\n",
            "zu\n",
            "t,\n",
            "Der\n",
            "tu\n",
            "ti\n",
            "r-\n",
            "li\n",
            "r-\n",
            "tu\n",
            "en\n",
            "r-\n",
            "che\n",
            "ru\n",
            "ll-\n",
            "[]\n",
            "ap\n",
            "tu\n",
            "ft\n",
            "ar\n",
            "au\n",
            "[]\n",
            "[]\n",
            "II\n",
            "[]\n",
            "n.\n",
            "un\n",
            "äf\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "e-\n",
            "de\n",
            "de\n",
            "äu\n",
            "nz\n",
            "Al\n",
            "am\n",
            "rt\n",
            "ei\n",
            "Ar\n",
            "f,\n",
            "Er\n",
            "t-\n",
            "af\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "forbidden = 0\n",
        "#allDatas = allDatas.reset_index()  # make sure indexes pair with number of rows\n",
        "for index, row in allDatas.iterrows():\n",
        "    #print(\"Index:\", index, \"ROw:\", row)\n",
        "    #unzip\n",
        "    _char = row['Char']\n",
        "    _image = row['Image']\n",
        "    try:\n",
        "        x[_char].append(_image)\n",
        "    #all_data = np.vstack((all_data, row[:]))\n",
        "\n",
        "    except:\n",
        "        forbidden = forbidden + 1\n",
        "        print(row[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0CsTFuB8T3b"
      },
      "outputs": [],
      "source": [
        "false_added = 40\n",
        "from skimage import util\n",
        "for element in x:\n",
        "    if len(x[element]) < max_size and len(x[element]) > 0:\n",
        "        old_len = len(x[element])\n",
        "        j = 0\n",
        "        for i in range(0, false_added-old_len):\n",
        "            vector = x[element][j][:]\n",
        "            tmp = vector[1:]      \n",
        "            tmp = np.asarray(tmp, dtype=np.float_, order='C')\n",
        "            noise = np.random.normal(0, .01, tmp.shape)\n",
        "            tmp = tmp + noise\n",
        "            tmp = np.asarray(tmp, dtype='<U32', order='C')  \n",
        "            vector[1:] = tmp\n",
        "            x[element].append(vector)\n",
        "            j = j + 1\n",
        "            if j >= old_len:\n",
        "                j = 0\n",
        "    if len(x[element]) > max_size:\n",
        "        x[element] = x[element][:max_size]\n",
        "\n",
        "table_of_chars = pd.DataFrame(columns = columns)\n",
        "for char in enable_chars:\n",
        "    for element2  in x[char]:\n",
        "        table_of_chars = table_of_chars.append({'Char': char, 'Image': element2}, ignore_index=True)\n",
        "\n",
        "\n",
        "X = table_of_chars['Image']\n",
        "Y = table_of_chars['Char']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=2077)\n",
        "np.savez_compressed(folder_path+ '/TrainingFiles/DataTrain(NotResized).npz',\n",
        "                    X_train = X_train,X_test = X_test, Y_train = Y_train,  Y_test = Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyGJTxiScwKt"
      },
      "source": [
        "#Funkcje umożliwiające stworzenie zbioru w docelowym rozmiarze przestrzeni cech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoWn2xWucjsN"
      },
      "outputs": [],
      "source": [
        "NPZFile = np.load(folder_path+ '/TrainingFiles/DataTrain(NotResized).npz', allow_pickle= True)\n",
        "X_train, Y_train, X_test, Y_test = [NPZFile[f] for f in ['X_train', 'y_train', \n",
        "                                    'X_test', 'y_test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOs-LwwbbZ8A"
      },
      "outputs": [],
      "source": [
        "def make_final_data_train_file(X, result_size):\n",
        "    # data_frame = pd.DataFrame(columns=['Vector'])\n",
        "    result_list = []\n",
        "    for x in X:\n",
        "        result_size_image = cv.resize(x, dsize=(result_size, result_size), interpolation=cv.INTER_CUBIC)\n",
        "        vector = result_size_image.reshape((1, (result_size*result_size)))\n",
        "\n",
        "        result_list.append(vector[0])\n",
        "        # data_frame = data_frame.append({'Vector': vector[0]}, ignore_index=True);\n",
        "    return np.array(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqgk6tA5Dog"
      },
      "outputs": [],
      "source": [
        "def save_to_npz_file(x_train, x_test, y_train, y_test, size):\n",
        "\n",
        "    result_file_path = folder_path+ '/TrainingFiles/Final/' + str(size) + '.npz'\n",
        "    np.savez_compressed(result_file_path,\n",
        "                    x_train = x_train,x_test = x_test, y_train = y_train,  y_test = y_test)\n",
        "    \n",
        "def load_to_npz_file(size):\n",
        "    NPZFile = np.load(folder_path+ '/TrainingFiles/Final/' + str(size) + '.npz', allow_pickle= True)\n",
        "    x_train, y_train, x_test, y_test = [NPZFile[f] for f in ['x_train', 'y_train', \n",
        "                                    'x_test', 'y_test']]\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80WTbCi1jCNQ"
      },
      "outputs": [],
      "source": [
        "def shuffle(x_train, x_test, y_train, y_test, seed):\n",
        "    x = np.vstack((x_train, x_test))\n",
        "    y = np.hstack([y_train, y_test])\n",
        "    new_x_train, new_x_test, new_y_train, new_y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=seed)\n",
        "    return new_x_train, new_x_test, new_y_train, new_y_test"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
